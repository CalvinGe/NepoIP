Torch device: cpu
Number of weights: 425624
Number of trainable weights: 425624
! Starting training ...

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      0    10        0.979        0.978     0.000651         6.46         10.1         5.71        0.259
      0    20         1.19         1.19     0.000392         7.22         11.1         4.43        0.202
      0    29         1.09         1.09     0.000221         6.71         10.6         3.33        0.151


  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse       e_rmse     e/N_rmse
! Initial Validation          0    9.127    0.005        0.991     0.000514        0.992         6.42         10.1         5.08        0.231
Wall time: 9.12765383347869
! Best model        0    0.992

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      1    10        0.825        0.822      0.00296         5.93         9.22         12.2        0.553
      1    20        0.474        0.465      0.00891         4.82         6.94         21.1        0.961
      1    30        0.586        0.585     0.000707         5.08         7.78         5.95        0.271
      1    40        0.521         0.52     0.000975         4.91         7.34         6.99        0.318
      1    50         0.46        0.458      0.00132          4.7         6.89         8.12        0.369
      1    60        0.407        0.406     0.000289         4.35         6.48          3.8        0.173
      1    70        0.354        0.353      0.00114         3.98         6.04         7.55        0.343
      1    80        0.335        0.335     0.000378         4.17         5.89         4.35        0.198
      1    90        0.376        0.375     0.000418         4.27         6.23         4.57        0.208
      1   100        0.359        0.358     0.000415         4.12         6.09         4.56        0.207
      1   110        0.191        0.191     0.000101         3.21         4.44         2.25        0.102
      1   120        0.343        0.342      0.00129         4.03         5.95         8.06        0.366
      1   130        0.281         0.28     0.000641         3.56         5.38         5.68        0.258
      1   140        0.212        0.211     0.000985         3.27         4.68         7.03        0.319
      1   150        0.297        0.297     0.000261         3.68         5.54         3.61        0.164
      1   160        0.227        0.227     3.65e-05         3.25         4.85         1.35       0.0615
      1   170        0.245        0.245     9.33e-05         3.46         5.04         2.16       0.0983
      1   180        0.245        0.244      0.00089         3.19         5.03         6.67        0.303
      1   190        0.197        0.197     0.000289         3.24         4.51         3.81        0.173
      1   200        0.189        0.189      0.00033         3.15         4.42         4.07        0.185
      1   210        0.278        0.278     0.000336         3.43         5.36          4.1        0.186
      1   220        0.215        0.214     0.000555         3.23         4.71         5.28         0.24
      1   230        0.185        0.184      0.00043         2.86         4.37         4.64        0.211
      1   231        0.227        0.227     0.000299         3.37         4.84         3.87        0.176

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      1    10        0.164        0.164     0.000266         2.86         4.11         3.65        0.166
      1    20        0.181        0.181     0.000417         2.97         4.32         4.57        0.208
      1    29         0.16         0.16     0.000417         2.78         4.06         4.57        0.208


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse       e_rmse     e/N_rmse
! Train               1  125.459    0.005        0.348     0.000994        0.349         3.93            6         7.06        0.321
! Validation          1  125.459    0.005        0.177     0.000335        0.177         2.87         4.28         4.09        0.186
Wall time: 125.45996706187725
! Best model        1    0.177

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      2    10        0.122        0.122     0.000689         2.49         3.55         5.87        0.267
      2    20        0.137        0.136     0.000357         2.51         3.76         4.24        0.193
      2    30        0.157        0.157      0.00011         2.62         4.03         2.35        0.107
      2    40        0.143        0.143     0.000515         2.67         3.85         5.08        0.231
      2    50        0.191         0.19      0.00113         2.92         4.43         7.52        0.342
      2    60        0.139        0.138      0.00054         2.65         3.78          5.2        0.237
      2    70        0.153        0.153     0.000337         2.66         3.98         4.11        0.187
      2    80        0.167        0.165      0.00157         2.66         4.14         8.88        0.404
      2    90        0.166        0.166     0.000531         2.84         4.14         5.16        0.235
      2   100        0.176        0.176     0.000561         2.63         4.26         5.29        0.241
      2   110        0.112        0.112     5.71e-05         2.27          3.4          1.7       0.0771
      2   120        0.101        0.101     0.000277         2.33         3.23         3.72        0.169
      2   130        0.163        0.162     0.000183         2.66          4.1         3.04        0.138
      2   140         0.15        0.149     0.000948         2.57         3.93         6.89        0.313
      2   150        0.159        0.158     0.000591         2.66         4.05         5.45        0.248
      2   160        0.116        0.115     0.000556         2.32         3.45         5.27        0.239
      2   170        0.103        0.103     0.000458         2.27         3.26          4.8        0.218
      2   180       0.0929       0.0925     0.000405         2.15         3.09          4.5        0.205
      2   190        0.116        0.116     0.000241         2.41         3.46         3.48        0.158
      2   200       0.0759       0.0753     0.000569         2.04         2.79         5.34        0.243
      2   210       0.0951       0.0948     0.000308          2.1         3.13         3.92        0.178
      2   220        0.116        0.115     0.000686         2.34         3.45         5.86        0.266
      2   230       0.0965       0.0961     0.000373         2.21         3.15         4.31        0.196
      2   231       0.0788       0.0787     0.000112         2.14         2.85         2.38        0.108

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      2    10       0.0816       0.0814     0.000218         2.03          2.9         3.31         0.15
      2    20       0.0805       0.0801     0.000368         2.01         2.88          4.3        0.195
      2    29       0.0737       0.0734     0.000291         1.96         2.76         3.82        0.174


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse       e_rmse     e/N_rmse
! Train               2  246.507    0.005        0.129     0.000457         0.13         2.46         3.66         4.79        0.218
! Validation          2  246.507    0.005       0.0845     0.000263       0.0848         2.01         2.96         3.63        0.165
Wall time: 246.50725190341473
! Best model        2    0.085

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      3    10       0.0929       0.0928     0.000105         2.19          3.1          2.3        0.105
      3    20       0.0845       0.0839     0.000626         2.01         2.95          5.6        0.254
      3    30        0.079       0.0788     0.000147         2.02         2.86         2.71        0.123
      3    40       0.0888       0.0886     0.000215         2.09         3.03         3.28        0.149
      3    50       0.0786       0.0781     0.000519         2.01         2.84         5.09        0.232
      3    60       0.0711       0.0707     0.000336         1.88         2.71          4.1        0.187
      3    70       0.0888       0.0887     2.97e-05         2.11         3.03         1.22       0.0554
      3    80        0.101        0.101     0.000225         2.16         3.23         3.35        0.152
      3    90       0.0731       0.0729     0.000245         1.83         2.75         3.49        0.159
      3   100        0.105        0.105     0.000187         2.23          3.3         3.06        0.139
      3   110       0.0983       0.0982      7.5e-05         2.05         3.19         1.93       0.0878
      3   120       0.0666       0.0665     0.000132          1.8         2.62         2.57        0.117
      3   130       0.0586       0.0585     8.03e-05         1.72         2.46            2       0.0911
      3   140       0.0657       0.0656     5.88e-05          1.8         2.61         1.72        0.078
      3   150       0.0536       0.0534     0.000177         1.66         2.35         2.99        0.136
      3   160       0.0619       0.0618     0.000109         1.79         2.53         2.34        0.106
      3   170       0.0618       0.0616     0.000189         1.78         2.52         3.08         0.14
      3   180       0.0597       0.0592      0.00044         1.74         2.48         4.69        0.213
      3   190       0.0649       0.0647     0.000153         1.81         2.59         2.77        0.126
      3   200       0.0903       0.0899     0.000374         2.02         3.05         4.33        0.197
      3   210       0.0777       0.0775     0.000217         1.96         2.83          3.3         0.15
      3   220       0.0804       0.0801     0.000349         1.97         2.88         4.18         0.19
      3   230       0.0625       0.0622     0.000266          1.8         2.54         3.65        0.166
      3   231       0.0473       0.0472     0.000106          1.6         2.21         2.32        0.106

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      3    10       0.0583       0.0582     0.000111         1.76         2.45         2.36        0.107
      3    20       0.0531       0.0528     0.000306         1.67         2.34         3.92        0.178
      3    29       0.0503       0.0501     0.000215         1.66         2.28         3.28        0.149


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse       e_rmse     e/N_rmse
! Train               3  357.659    0.005       0.0776     0.000272       0.0779         1.95         2.84         3.69        0.168
! Validation          3  357.659    0.005       0.0578     0.000188        0.058          1.7         2.45         3.07         0.14
Wall time: 357.65966429561377
! Best model        3    0.058

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      4    10       0.0551       0.0544     0.000736         1.61         2.37         6.07        0.276
      4    20       0.0579       0.0578     0.000187         1.76         2.44         3.07        0.139
      4    30       0.0656       0.0655     3.39e-05         1.74          2.6          1.3       0.0591
      4    40       0.0475       0.0474     0.000181         1.62         2.21         3.01        0.137
      4    50       0.0466       0.0462     0.000381         1.56         2.19         4.37        0.199
      4    60       0.0645       0.0643     0.000215         1.82         2.58         3.27        0.149
      4    70       0.0618       0.0616     0.000198         1.82         2.52         3.15        0.143
      4    80       0.0637       0.0633      0.00039         1.79         2.56         4.43        0.201
      4    90       0.0527       0.0525     0.000207         1.59         2.33         3.23        0.147
      4   100         0.06       0.0599     0.000149         1.76         2.49         2.72        0.124
      4   110       0.0753       0.0751     0.000118          1.8         2.79         2.43         0.11
      4   120       0.0541        0.054     8.79e-05          1.6         2.36         2.09       0.0951
      4   130       0.0582       0.0577     0.000517         1.72         2.44         5.09        0.231
      4   140       0.0496       0.0495     0.000119         1.57         2.26         2.44        0.111
      4   150       0.0696       0.0692      0.00045         1.87         2.67         4.74        0.215
      4   160       0.0482       0.0482     7.06e-05         1.65         2.23         1.89       0.0858
      4   170       0.0647       0.0645     0.000186         1.78         2.58         3.04        0.138
      4   180       0.0539       0.0536     0.000254         1.71         2.36         3.57        0.162
      4   190       0.0717       0.0717     9.82e-06         1.86         2.72        0.703       0.0319
      4   200       0.0432       0.0429     0.000316         1.48         2.11         3.98        0.181
      4   210       0.0405       0.0405     4.07e-05         1.48         2.05         1.42       0.0646
      4   220       0.0581       0.0579     0.000233         1.77         2.45         3.41        0.155
      4   230       0.0601       0.0598     0.000304          1.7         2.49          3.9        0.177
      4   231        0.069       0.0682     0.000807         1.82         2.66         6.36        0.289

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      4    10       0.0443       0.0442     9.05e-05         1.55         2.14         2.13       0.0967
      4    20       0.0428       0.0425     0.000311          1.5          2.1         3.95        0.179
      4    29       0.0427       0.0425     0.000225         1.56          2.1         3.36        0.153


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse       e_rmse     e/N_rmse
! Train               4  473.407    0.005       0.0597     0.000223       0.0599         1.72         2.49         3.33        0.151
! Validation          4  473.407    0.005       0.0455     0.000179       0.0457         1.52         2.17         2.99        0.136
Wall time: 473.40746903419495
! Best model        4    0.046

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      5    10       0.0609       0.0608      0.00014         1.79         2.51         2.65         0.12
      5    20       0.0632       0.0625     0.000709         1.74         2.54         5.95        0.271
      5    30       0.0352       0.0352     2.85e-05         1.39         1.91         1.19        0.054
      5    40       0.0607       0.0607     7.24e-05         1.69         2.51          1.9       0.0862
      5    50       0.0594       0.0593     6.88e-05         1.68         2.48         1.86       0.0845
      5    60       0.0465        0.046     0.000474         1.62         2.18         4.89        0.222
      5    70       0.0515       0.0513     0.000174         1.59          2.3         2.95        0.134
      5    80       0.0484       0.0482     0.000151         1.47         2.23         2.75        0.125
      5    90       0.0511        0.051     0.000142         1.61          2.3         2.67        0.121
      5   100       0.0447       0.0445     0.000154          1.5         2.15         2.78        0.126
      5   110       0.0395       0.0393     0.000168         1.49         2.02         2.89        0.132
      5   120       0.0356       0.0355     6.77e-05         1.36         1.92         1.83       0.0832
      5   130       0.0363       0.0362     2.45e-05         1.43         1.94         1.11       0.0505
      5   140       0.0427       0.0426     0.000102         1.52          2.1         2.26        0.103
      5   150       0.0515       0.0514     9.55e-05         1.62         2.31         2.19       0.0994
      5   160       0.0584       0.0579     0.000466         1.62         2.45         4.82        0.219
      5   170       0.0516       0.0512     0.000368         1.57          2.3          4.3        0.195
      5   180       0.0405       0.0403     0.000149         1.39         2.04         2.74        0.125
      5   190       0.0472        0.047     0.000124         1.59         2.21         2.49        0.113
      5   200       0.0366       0.0362     0.000332         1.44         1.94         4.08        0.185
      5   210       0.0292        0.029      0.00019         1.22         1.73         3.09         0.14
      5   220       0.0339       0.0338     4.06e-05         1.38         1.87         1.42       0.0647
      5   230       0.0548       0.0543     0.000445         1.54         2.37         4.71        0.214
      5   231       0.0478       0.0478     1.41e-05         1.58         2.22        0.839       0.0381

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse       e_rmse     e/N_rmse
      5    10       0.0347       0.0347     5.83e-05         1.37         1.89         1.71       0.0776
      5    20       0.0351       0.0348     0.000298         1.36          1.9         3.86        0.176
      5    29       0.0376       0.0374     0.000191         1.45         1.97         3.09         0.14


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse       e_rmse     e/N_rmse
! Train               5  586.778    0.005       0.0459     0.000203       0.0461         1.53         2.18         3.19        0.145
! Validation          5  586.778    0.005       0.0369     0.000155        0.037         1.37         1.95         2.79        0.127
Wall time: 586.7783546708524
! Best model        5    0.037
! Stop training: max epochs
Wall time: 586.9436511658132
Cumulative wall time: 586.9436511658132
